{"meta":{"title":"littlepig flying","subtitle":null,"description":"生活如此美好~~","author":"miracle li","url":"http://www.blog.littlepig.tech"},"pages":[{"title":"categories","date":"2018-06-14T01:22:04.000Z","updated":"2018-06-14T09:43:16.262Z","comments":true,"path":"categories/index.html","permalink":"http://www.blog.littlepig.tech/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-06-14T01:21:35.000Z","updated":"2018-06-14T09:44:51.401Z","comments":true,"path":"tags/index.html","permalink":"http://www.blog.littlepig.tech/tags/index.html","excerpt":"","text":""},{"title":"about","date":"2018-06-13T09:16:31.000Z","updated":"2018-06-13T09:17:05.989Z","comments":true,"path":"about/index.html","permalink":"http://www.blog.littlepig.tech/about/index.html","excerpt":"","text":"本文链接：&lt;%= post.title %&gt; 作者：令狐葱 出处：http://jiji262.github.io/本文基于 知识共享署名-相同方式共享 4.0 国际许可协议发布，欢迎转载，演绎或用于商业目的，但是必须保留本文的署名令狐葱及链接。"}],"posts":[{"title":"Hbase文档1-前言","slug":"Hbase文档1-前言","date":"2018-06-01T13:01:24.000Z","updated":"2018-06-19T06:14:50.502Z","comments":true,"path":"2018/06/01/Hbase文档1-前言/","link":"","permalink":"http://www.blog.littlepig.tech/2018/06/01/Hbase文档1-前言/","excerpt":"","text":"本文是Hbase官翻系列文章，官方文档在http://hbase.apache.org/book.html后查看本文采用段落式英文 段落式中文格式翻译。 Preface 前言This is the official reference guide for the HBase version（3.0.0-SNAPSHOT） it ships with. 这是HBase3.0.0-SNAPSHOT附带的的官方参考指南。 Herein you will find either the definitive documentation on an HBase topic as of its standing when the referenced HBase version shipped, or it will point to the location in Javadoc or JIRA where the pertinent information can be found. 当此版本的Hbase发布时，你可以在这里找到此版本的Hbase主题的最终文档。同时，它也会指向Javadoc 或者JIRA的相关信息的位置。 About This Guide 关于本指南This reference guide is a work in progress. The source for this guide can be found in the _src/main/asciidoc directory of the HBase source. This reference guide is marked up using AsciiDoc from which the finished guide is generated as part of the ‘site’ build target. 这个参考指南正在编著中。在Hbase 源代码的 _src/main/asciidoc目录下能找到此指南的源代码。该源码用AsciiDoc编著， AsciiDoc是以生成简洁易懂的指南为目的网站 Run1mvn site to generate this documentation. Amendments and improvements to the documentation are welcomed. Click this link to file a new documentation bug against Apache HBase with some values pre-selected. 运行 mvn site 生成这个文档。欢迎修正还改进这个文档。点击此链接发送一个与ApacheHbase相冲突的预先选定参数的bug列表。 Contributing to the Documentation 向文档贡献你的力量For an overview of AsciiDoc and suggestions to get started contributing to the documentation, see the relevant section later in this documentation. 了解了AsciiDoc以后开始对本文档贡献你的建议吧，在文档后边查看相关部分。 Heads-up if this is your first foray into the world of distributed computing…​ 警告第一次进入分布式计算系统的人…If this is your first foray into the wonderful world of Distributed Computing, then you are in for some interesting times. First off, distributed systems are hard; making a distributed system hum requires a disparate skillset that spans systems (hardware and software) and networking. 如果这是你第一次进入分布式计算的世界，你将要进入一个有趣的时代。首先分布式系统很难；完成一个分布式系统需要一些不相关的技能组包括软件、硬件和网络。 Your cluster’s operation can hiccup because of any of a myriad set of reasons from bugs in HBase itself through misconfigurations — misconfiguration of HBase but also operating system misconfigurations — through to hardware problems whether it be a bug in your network card drivers or an underprovisioned RAM bus (to mention two recent examples of hardware issues that manifested as “HBase is slow”). You will also need to do a recalibration if up to this your computing has been bound to a single box. Here is one good starting point: Fallacies of Distributed Computing. 你的集群可能因为好多问题导致故障，无论是Hbase配置引起的，或是操作系统配置引起的故障。举例说硬件部分 网卡驱动或是 an underprovisioned RAM bus （两个最常见的硬件问题引起“Hbase 很慢”）。你也需要重新学习，如果你一直在写单机程序的话。这将是一个好的开始：《分布式系统的谬论》 That said, you are welcome.It’s a fun place to be.Yours, the HBase Community. 也就是说欢迎你，这是一个很意思的地方。Hbase 社区欢迎你。 Reporting Bugs Bug提交Please use JIRA to report non-security-related bugs. 请使用JIRA报告非安全相关的bug。 To protect existing HBase installations from new vulnerabilities, please do not use JIRA to report security-related bugs. Instead, send your report to the mailing list private@apache.org, which allows anyone to send messages, but restricts who can read them. Someone on that list will contact you to follow up on your report. 为了保护已经使用Hbase的安装者，请不要用JIRA提交安全相关的bug。请发送报告到private@apache.org列表，它允许任何人发送报告，并限制读取。邮件拥有者会联系你跟踪此报告。 Support and Testing Expectations 支持和测试的期望The phrases /supported/, /not supported/, /tested/, and /not tested/ occur several places throughout this guide. In the interest of clarity, here is a brief explanation of what is generally meant by these phrases, in the context of HBase.Commercial technical support for Apache HBase is provided by many Hadoop vendors. This is not the sense in which the term /support/ is used in the context of the Apache HBase project. The Apache HBase team assumes no responsibility for your HBase clusters, your configuration, or your data. 指南中标注了 supported 、not supported 、tested 、not tested。为了清晰可见，这里有一个明确的定义在Hbase文档中这些短语的意思。很多hadoop供应商提供了针对于Apache HBase的商业技术支持，这不是Hbase中support的使用场景。Hbase 团队对于你的Hbase 集群、配置和数据是没有责任的。 SupportedIn the context of Apache HBase, /supported/ means that HBase is designed to work in the way described, and deviation from the defined behavior or functionality should be reported as a bug. 在本文档中，supported 意味着Hbase被设计成按照描述的方式运行。偏离了明确的行为和功能应该被视为一个Bug。 Not SupportedIn the context of Apache HBase, /not supported/ means that a use case or use pattern is not expected to work and should be considered an antipattern. If you think this designation should be reconsidered for a given feature or use pattern, file a JIRA or start a discussion on one of the mailing lists. 本文当中 not supported 意味着 这个用例或是模式不会被运行，并且被视为一个反模式。如果你认为这个设计对于一种给定的功能或是用例应该被重新考虑，请创建一个JIRA或是开始一个讨论在邮件列表中的某个邮件下。 TestedIn the context of Apache HBase, /tested/ means that a feature is covered by unit or integration tests, and has been proven to work as expected. 文档中的 tesetd 意味着 这个功能已经被单元或是集成测试了，并且已经被证明可以按照预期工作。 Not TestedIn the context of Apache HBase, /not tested/ means that a feature or use pattern may or may not work in a given way, and may or may not corrupt your data or cause operational issues. It is an unknown, and there are no guarantees. If you can provide proof that a feature designated as /not tested/ does work in a given way, please submit the tests and/or the metrics so that other users can gain certainty about such features or use patterns. 文档中的 Not tested 意味着这个功能或是用例有时不会正确运行，并且有时会引起数据错误，或是操作问题。这个功能是一个未知的，并且没有保证。如果你有证据能证明这个功能在某种方式下可以正确运行，请提交这个测试或是指标，让其他用户可以肯定使用这个功能或用例。","categories":[{"name":"hadoop","slug":"hadoop","permalink":"http://www.blog.littlepig.tech/categories/hadoop/"}],"tags":[{"name":"官翻系列","slug":"官翻系列","permalink":"http://www.blog.littlepig.tech/tags/官翻系列/"}]},{"title":"Hbase文档2-QuickStart","slug":"Hbase文档2-QuickStart","date":"2018-06-01T13:01:24.000Z","updated":"2018-06-19T06:27:52.574Z","comments":true,"path":"2018/06/01/Hbase文档2-QuickStart/","link":"","permalink":"http://www.blog.littlepig.tech/2018/06/01/Hbase文档2-QuickStart/","excerpt":"","text":"本文是Hbase官翻系列文章，官方文档在http://hbase.apache.org/book.html后查看本文采用段落式英文 段落式中文格式翻译。 Getting Started 开始Introduction 简介Quickstart will get you up and running on a single-node, standalone instance of HBase. 快速开始将要带你运行一个单节点的、独立的Hbase实例。 Quick Start - Standalone HBase 快速开始 - 单节点的Hbase实例This section describes the setup of a single-node standalone HBase. A standalone instance has all HBase daemons — the Master, RegionServers, and ZooKeeper — running in a single JVM persisting to the local filesystem. It is our most basic deploy profile. We will show you how to create a table in HBase using the hbase shell CLI, insert rows into the table, perform put and scan operations against the table, enable or disable the table, and start and stop HBase.Apart from downloading HBase, this procedure should take less than 10 minutes. 这一部分描述了设置（single-node standalone）单节点独立Hbase的步骤。一个单节点独立的Hbase实例包含所有的Hbase 守护进程 - the Master,RegionServers,and Zookeeper - 运行在一个单JVM、本地的文件系统中。这是一个最基础的部署文件。我们将要展示怎么在Hbase中通过Hbase shell CII 创建一个表、在表中插入行、在表中执行put和scan操作，enable 或是 disable 一个表、开始或停止Hbase服务。除了下载Hbase，这些过程应该不超过10分钟。 JDK Version Requirements JDK 版本要求HBase requires that a JDK be installed. See Java for information about supported JDK versions.Hbase需要JDK被事先安装。通过JAVA信息查看支持的JDK版本。 Get Started with HBase HBase 开始Procedure: Download, Configure, and Start HBase in Standalone Mode Choose a download site from this list of Apache Download Mirrors. Click on the suggested top link. This will take you to a mirror of HBase Releases. Click on the folder named stable and then download the binary file that ends in .tar.gz to your local filesystem. Do not download the file ending in src.tar.gz for now.过程： 下载、配置、在单机模式下启动HBase Extract the downloaded file, and change to the newly-created directory. 12$ tar xzvf hbase-3.0.0-SNAPSHOT-bin.tar.gz$ cd hbase-3.0.0-SNAPSHOT/ You are required to set the JAVA_HOME environment variable before starting HBase. You can set the variable via your operating system’s usual mechanism, but HBase provides a central mechanism, conf/hbase-env.sh. Edit this file, uncomment the line starting with JAVA_HOME, and set it to the appropriate location for your operating system. The JAVA_HOME variable should be set to a directory which contains the executable file bin/java. Most modern Linux operating systems provide a mechanism, such as /usr/bin/alternatives on RHEL or CentOS, for transparently switching between versions of executables such as Java. In this case, you can set JAVA_HOME to the directory containing the symbolic link to bin/java, which is usually /usr. 1JAVA_HOME=/usr Edit conf/hbase-site.xml, which is the main HBase configuration file. At this time, you need to specify the directory on the local filesystem where HBase and ZooKeeper write data and acknowledge some risks. By default, a new directory is created under /tmp. Many servers are configured to delete the contents of /tmp upon reboot, so you should store the data elsewhere. The following configuration will store HBase’s data in the hbase directory, in the home directory of the user called testuser. Paste the tags beneath the tags, which should be empty in a new HBase install.Example 1. Example hbase-site.xml for Standalone HBase 12345678910111213141516171819202122232425&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;file:///home/testuser/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; &lt;value&gt;/home/testuser/zookeeper&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;description&gt; Controls whether HBase will check for stream capabilities (hflush/hsync). Disable this if you intend to run on LocalFileSystem, denoted by a rootdir with the &apos;file://&apos; scheme, but be mindful of the NOTE below. WARNING: Setting this to false blinds you to potential data loss and inconsistent system state in the event of process and/or node failures. If HBase is complaining of an inability to use hsync or hflush it&apos;s most likely not a false positive. &lt;/description&gt; &lt;/property&gt;&lt;/configuration&gt; You do not need to create the HBase data directory. HBase will do this for you. If you create the directory, HBase will attempt to do a migration, which is not what you want.The hbase.rootdir in the above example points to a directory in the local filesystem. The ‘file://‘ prefix is how we denote local filesystem. You should take the WARNING present in the configuration example to heart. In standalone mode HBase makes use of the local filesystem abstraction from the Apache Hadoop project. That abstraction doesn’t provide the durability promises that HBase needs to operate safely. This is fine for local development and testing use cases where the cost of cluster failure is well contained. It is not appropriate for production deployments; eventually you will lose data. To home HBase on an existing instance of HDFS, set the hbase.rootdir to point at a directory up on your instance: e.g. hdfs://namenode.example.org:8020/hbase. For more on this variant, see the section below on Standalone HBase over HDFS. The bin/start-hbase.sh script is provided as a convenient way to start HBase. Issue the command, and if all goes well, a message is logged to standard output showing that HBase started successfully. You can use the jps command to verify that you have one running process called HMaster. In standalone mode HBase runs all daemons within this single JVM, i.e. the HMaster, a single HRegionServer, and the ZooKeeper daemon. Go to http://localhost:16010 to view the HBase Web UI.Java needs to be installed and available. If you get an error indicating that Java is not installed, but it is on your system, perhaps in a non-standard location, edit the conf/hbase-env.sh file and modify the JAVA_HOME setting to point to the directory that contains bin/java on your system. Procedure: Use HBase For the First Time Connect to HBase.Connect to your running instance of HBase using the hbase shell command, located in the bin/ directory of your HBase install. In this example, some usage and version information that is printed when you start HBase Shell has been omitted. The HBase Shell prompt ends with a &gt; character. 12$ ./bin/hbase shellhbase(main):001:0&gt; Display HBase Shell Help Text.Type help and press Enter, to display some basic usage information for HBase Shell, as well as several example commands. Notice that table names, rows, columns all must be enclosed in quote characters. Create a table.Use the create command to create a new table. You must specify the table name and the ColumnFamily name. 123hbase(main):001:0&gt; create &apos;test&apos;, &apos;cf&apos;0 row(s) in 0.4170 seconds=&gt; Hbase::Table - test List Information About your TableUse the list command to confirm your table exists 12345678910111213141516hbase(main):002:0&gt; list &apos;test&apos;TABLEtest1 row(s) in 0.0180 seconds=&gt; [&quot;test&quot;]Now use the describe command to see details, including configuration defaultshbase(main):003:0&gt; describe &apos;test&apos;Table test is ENABLEDtestCOLUMN FAMILIES DESCRIPTION&#123;NAME =&gt; &apos;cf&apos;, VERSIONS =&gt; &apos;1&apos;, EVICT_BLOCKS_ON_CLOSE =&gt; &apos;false&apos;, NEW_VERSION_BEHAVIOR =&gt; &apos;false&apos;, KEEP_DELETED_CELLS =&gt; &apos;FALSE&apos;, CACHE_DATA_ON_WRITE =&gt;&apos;false&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, TTL =&gt; &apos;FOREVER&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, REPLICATION_SCOPE =&gt; &apos;0&apos;, BLOOMFILTER =&gt; &apos;ROW&apos;, CACHE_INDEX_ON_WRITE =&gt; &apos;false&apos;, IN_MEMORY =&gt; &apos;false&apos;, CACHE_BLOOMS_ON_WRITE =&gt; &apos;false&apos;, PREFETCH_BLOCKS_ON_OPEN =&gt; &apos;false&apos;, COMPRESSION =&gt; &apos;NONE&apos;, BLOCKCACHE =&gt; &apos;true&apos;, BLOCKSIZE =&gt; &apos;65536&apos;&#125;1 row(s)Took 0.9998 seconds Put data into your table.To put data into your table, use the put command. 123456hbase(main):003:0&gt; put &apos;test&apos;, &apos;row1&apos;, &apos;cf:a&apos;, &apos;value1&apos;0 row(s) in 0.0850 secondshbase(main):004:0&gt; put &apos;test&apos;, &apos;row2&apos;, &apos;cf:b&apos;, &apos;value2&apos;0 row(s) in 0.0110 secondshbase(main):005:0&gt; put &apos;test&apos;, &apos;row3&apos;, &apos;cf:c&apos;, &apos;value3&apos;0 row(s) in 0.0100 seconds Here, we insert three values, one at a time. The first insert is at row1, column cf:a, with a value of value1. Columns in HBase are comprised of a column family prefix, cf in this example, followed by a colon and then a column qualifier suffix, a in this case. Scan the table for all data at once.One of the ways to get data from HBase is to scan. Use the scan command to scan the table for data. You can limit your scan, but for now, all data is fetched. 123456hbase(main):006:0&gt; scan &apos;test&apos;ROW COLUMN+CELL row1 column=cf:a, timestamp=1421762485768, value=value1 row2 column=cf:b, timestamp=1421762491785, value=value2 row3 column=cf:c, timestamp=1421762496210, value=value33 row(s) in 0.0230 seconds Get a single row of data.To get a single row of data at a time, use the get command. 1234hbase(main):007:0&gt; get &apos;test&apos;, &apos;row1&apos;COLUMN CELL cf:a timestamp=1421762485768, value=value11 row(s) in 0.0350 seconds Disable a table.If you want to delete a table or change its settings, as well as in some other situations, you need to disable the table first, using the disable command. You can re-enable it using the enable command. 1234567hbase(main):008:0&gt; disable &apos;test&apos;0 row(s) in 1.1820 secondshbase(main):009:0&gt; enable &apos;test&apos;0 row(s) in 0.1770 secondsDisable the table again if you tested the enable command above:hbase(main):010:0&gt; disable &apos;test&apos;0 row(s) in 1.1820 seconds Drop the table.To drop (delete) a table, use the drop command. 12hbase(main):011:0&gt; drop &apos;test&apos;0 row(s) in 0.1370 seconds Exit the HBase Shell.To exit the HBase Shell and disconnect from your cluster, use the quit command. HBase is still running in the background. Procedure: Stop HBase In the same way that the bin/start-hbase.sh script is provided to conveniently start all HBase daemons, the bin/stop-hbase.sh script stops them. 123$ ./bin/stop-hbase.shstopping hbase....................$ After issuing the command, it can take several minutes for the processes to shut down. Use the jps to be sure that the HMaster and HRegionServer processes are shut down. The above has shown you how to start and stop a standalone instance of HBase. In the next sections we give a quick overview of other modes of hbase deploy.","categories":[{"name":"hadoop","slug":"hadoop","permalink":"http://www.blog.littlepig.tech/categories/hadoop/"}],"tags":[{"name":"官翻系列","slug":"官翻系列","permalink":"http://www.blog.littlepig.tech/tags/官翻系列/"}]},{"title":"Cloudera 5.13.3 离线安装","slug":"Cloudera 安装","date":"2018-05-01T13:01:24.000Z","updated":"2018-06-15T01:24:11.239Z","comments":true,"path":"2018/05/01/Cloudera 安装/","link":"","permalink":"http://www.blog.littlepig.tech/2018/05/01/Cloudera 安装/","excerpt":"","text":"离线安装cloudera 5.13.3本版本的cloudera默认自带spark1.6 升级到spark2 软件版本说明 服务器版本 3.10.0-327.el7.centos cloudera 5.13.3 cloudera manager 5.13.3 下文简称CM jdk 1.8.0_172 mysql 5.7.17 相应包下载地址 cm镜像地址 http://archive.cloudera.com/cm5/cm/5/cloudera-manager-centos7-cm5.13.3_x86_64.tar.gz CDH镜像地址：(注意与服务器版本保持一致，我的是centos el7 所以下载el7的包) http://archive.cloudera.com/cdh5/parcels/5.13.3/CDH-5.13.3-1.cdh5.13.3.p0.2-el7.parcelhttp://archive.cloudera.com/cdh5/parcels/5.13.3/CDH-5.13.3-1.cdh5.13.3.p0.2-el7.parcel.sha1http://archive.cloudera.com/cdh5/parcels/5.13.3/manifest.json mysql 下载地址 在镜像http://mirrors.sohu.com/mysql/MySQL-5.7/中下载相应包mysql-community-client-5.7.17-1.el7.x86_64.rpmmysql-community-libs-5.7.17-1.el7.x86_64.rpmmysql-community-common-5.7.17-1.el7.x86_64.rpmmysql-community-libs-compat-5.7.21-1.el7.x86_64.rpmmysql-community-server-5.7.21-1.el7.x86_64.rpmhttp://dev.mysql.com/downloads/connector/j/ 下载mysql 的jdbc驱动 环境配置 网络配置（所有节点） 修改各个主机名，主机名不要有下划线，我这是6台机器，主机名分别是hadoop0~hadoop51$ vi /etc/hostname 修改network 并使之生效1234567vi /etc/sysconfig/network修改为：NETWORKING=yesHOSTNAME=hadoopX使之生效：source /etc/sysconfig/network 修改hosts12345678vi /etc/hosts添加：10.10.XX.130 hadoop010.10.XX.131 hadoop110.10.XX.132 hadoop210.10.XX.133 hadoop310.10.XX.134 hadoop410.10.XX.135 hadoop5 重启网络1$service network restart 设置SSH免密登录（所有节点） 在所有节点执行1234567891011121314每台机器执行，一直回车 生成无密码密钥$ssh-keygen -t rsa将公钥添加到认证文件中：cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys 设置authorized_keys的访问权限：chmod 600 ~/.ssh/authorized_keys将密钥发送到其他需要免密登录的机器中 每台机器都要执行比如 在hadoop0 中执行时要执行5次，修改hadoop1 ~hadoop5cat ~/.ssh/id_rsa.pub | ssh -p 22 root@hadoop1 ‘cat &gt;&gt; ~/.ssh/authorized_keys’测试 在hadoop0 中执行ssh hadoop1不需要密码登录到hadoop1中 关闭防火墙 (所有节点)1234//临时关闭systemctl stop firewalld//禁止开机启动systemctl disable firewalld 设置集群时间同步 （所有节点）1234567891011121314151.在集群中所有节点上安装ntpyum install ntp2.所有节点设置时区，这里设置为中国所用时间timedatectl set-timezone Asia/Shanghai3.在server节点上启动ntp服务systemctl start ntpdsystemctl enable ntpd4.在server节点上设置现在的准确时间timedatectl set-time HH:MM:SS5.在server节点上设置其ntp服务器为其自身，同时设置可以接受连接服务的客户端，是通过更改/etc/ntp.conf文件来实现的，其中server设置127.127.1.0为其自身vi /etc/ntp.conf 123456.重启ntpd服务systemctl restart ntpd7.在client节点上设置ntp服务器为server节点vi /etc/ntp.conf 123456789108.在client节点上同步server的时间ntpdate hadoop09.client节点启动ntpd服务systemctl start ntpdsystemctl enable ntpd10.所有节点启动时间同步timedatectl set-ntp yes 安装 jdk （所有节点）注意一定放在/usr/java/下！！！123456789101112131415161718191.卸载自带的OpenJdkrpm -qa | grep java #查询java相关的包rpm -e --nodeps XXX #包名卸载之。2. 创建解压目录mkdir -p /usr/java/3. 在jdk压缩包所在目录下执行tar -zxvf jdk-8u172-linux-x64.tar.gz -C /usr/java/4、修改环境变量vi /etc/profile添加：export JAVA_HOME=/usr/java/jdk1.8.0_172export JRE_HOME=$JAVA_HOME/jreexport CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib/tools.jarexport PATH=$JAVA_HOME/bin:$PATH5、使之生效source /etc/profile6、验证java -version显示正确版本号 安装 mysql （主节点）123456789101112131415161718192021222324251. centos 7 默认安装的是mariadb，需要先卸载再安装rpm -qa | grep mariadb #查看安装信息rpm -e mariadb-libs* --nodeps #根据查找到的软件包信息卸载2. 安装mysqlyum install libnuma*rpm -ivh mysql-community-common-5.7.17-1.el7.x86_64.rpmrpm -ivh mysql-community-libs-5.7.17-1.el7.x86_64.rpmrpm -ivh mysql-community-client-5.7.17-1.el7.x86_64.rpmrpm -ivh mysql-community-server-5.7.17-1.el7.x86_64.rpm3. 设置开机启动chkconfig mysqld on #开机启动service mysqld start #启动mysql服务，mysqladmin -u root password &apos;xxxx&apos; #设置root密码4、进入mysql命令myslq -uroot -p #输入密码进入mysql控制台5、创建数据库create database hue DEFAULT CHARSET utf8 COLLATE utf8_general_ci; #hivecreate database hive DEFAULT CHARSET utf8 COLLATE utf8_general_ci;#activity monitorcreate database amon DEFAULT CHARSET utf8 COLLATE utf8_general_ci;create database oozie DEFAULT CHARSET utf8 COLLATE utf8_general_ci;6. 授权root用户在主节点拥有所有数据库的访问权限grant all privileges on *.* to &apos;root&apos;@&apos;n1&apos; identified by &apos;xxxx&apos; with grant option;flush privileges; 安装 cm+cdh 主节点解压cloudera-manager-centos7-cm5.13.3_x86_64.tar.gz 到/opt下 1tar -zxvf cloudera-manager-centos7-cm5.13.3_x86_64.tar.gz -C /opt/ 为cm 建立mysql数据库 1234561. 将下载的mysql jdbc驱动包解压，并将 jar复制到 cm相应目录下tar -zxvf mysql-connector-java-5.1.45.tar.gzcp mysql-connector-java-5.1.45-bin.jar /opt/cm-5.13.3/share/cmf/lib2.在主节点初始化cm数据库/opt/cm-5.13.3/share/cmf/schema/scm_prepare_database.sh mysql cm -hlocalhost -uroot -pxxxx --scm-host localhost scm scm scm agent 配置 123vi /opt/cm-5.13.3/etc/cloudera-scm-agent/config.ini修改server_host为主节点的主机名 同步agent 到其他节点 同步到hadoop1-hadoop5 1scp -r /opt/cm-5.13.3 root@hadoop1:/opt/ 在所有节点创建cloudera-scm用户 1useradd --system --home=/opt/cm-5.13.3/run/cloudera-scm-server/ --no-create-home --shell=/bin/false --comment &quot;Cloudera SCM User&quot; cloudera-scm 准备 CDH parcels 1234567将下载的CDH相关parcel copy到/opt/cloudera/parcel-repocp CDH-5.13.3-1.cdh5.13.3.p0.2-el7.parcel /opt/cloudera/parcel-repo/cp CDH-5.13.3-1.cdh5.13.3.p0.2-el7.parcel.sha1 /opt/cloudera/parcel-repo/cp manifest.json /opt/cloudera/parcel-repo/修改CDH-5.13.3-1.cdh5.13.3.p0.2-el7.parcel.sha1 为CDH-5.13.3-1.cdh5.13.3.p0.2-el7.parcel.shamv CDH-5.13.3-1.cdh5.13.3.p0.2-el7.parcel.sha1 CDH-5.13.3-1.cdh5.13.3.p0.2-el7.parcel.sha 启动cm 12345相关启动脚本 主节点启动server+agent 其他节点启动agent通过/opt/cm-5.13.3/etc/init.d/cloudera-scm-server start启动服务端。通过/opt/cm-5.13.3/etc/init.d/cloudera-scm-agent start启动Agent服务。 cdh 安装配置启动cm后就可以在cm控制台中安装cdh并配置了。由于当时安装时没有相关截图，就不写啦期间会遇到连接mysql时报错，需要相应python包的安装其他问题通过提示可解决","categories":[{"name":"hadoop","slug":"hadoop","permalink":"http://www.blog.littlepig.tech/categories/hadoop/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.blog.littlepig.tech/tags/技术/"}]}]}